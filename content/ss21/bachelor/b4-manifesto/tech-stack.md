+++
title = "Tech Stack"
weight = 5
+++

{{<image src="manifesto_tech_stack.png" alt="Tech Stack Manifesto">}}

---

{{<section title="Jira">}}

Mit Hilfe von Jira konnten wir eine Übersicht unserer Aufgaben und der Verteilung derer gestalten die sowohl der Konzept- sowie der Softwareentwicklung dienten.
{{</section>}}

{{<section title="Discord">}}

Um eine ständige und kurzfristige Kommunikation aufrecht zu erhalten, haben wir uns auf Discord geeinigt Dort verwendeten wir die Text- sowie auch auch die Sprachkanäle um uns auszutauschen.
{{</section>}}

{{<section title="Miro">}}

Miro diente als Ideensammlungsportal und half uns, wenn wir mal ein "Schwarzes Brett" zum diskutieren brauchten.
{{</section>}}

{{<section title="GitHub">}}

Über Github haben wir den Code geteilt. Das hat es uns ermöglicht zeitgleich am Projekt Manifesto zu arbeiten.
{{</section>}}

{{<section title="Kafka und Docker">}}

Da wir alle Probleme vermeiden wollten, die mit der Installation von Tools verbunden sind, die eine gewisse Konfiguration erfordern, verwendeten wir Docker, um unsere **Kafka**-Instanz zu betreiben, die für die Verbindung der Python-Anwendung mit der NodeJs-Anwendung verantwortlich war.
{{</section>}}

{{<section title="Python und OpenCV">}}

Der **erste Schritt** der Reise war die Auswahl eines **Frameworks**, das uns bei der Objekterkennung hilft. Wir hatten sehr **wenig Erfahrung** mit Computer Vision, also war es notwendig, zuerst **selbstständig zu recherchieren** und wir landeten bei zwei Kandidaten: **OpenCv mit Python oder C++**
und wir entschieden uns für Python.
Python hat in den letzten Jahren eine große **Popularität** unter Entwicklern erlangt. Außerdem wird es vom Raspberry Pi nativ unterstützt, so dass es einfacher ist, eine Python-App auf ihm zu installieren.
Es hat eine sehr einfache Syntax und eine steile Lernkurve, so dass es einfach war, die Grundlagen schnell zu erlernen.

{{</section>}}

{{<section title="Node.js">}}

Die Auswertung der Daten, die wir vom Raspberry pi erhalten haben, ist der **wichtigste** Teil des Projekts.
Auch hier hatten wir zwei Kandidaten: **NodeJs und Java**.
Da es aber den Vorteil hat, nicht zu blockieren und weniger Ressourcen zu verbrauchen als Java, entschieden wir uns für NodeJs.
{{</section>}}

{{<section title="Ableton live">}}

Ableton ist eine Sequencer-Software, die eine Musikproduktion ermöglicht. Mit Plugins ist es möglich eigene Applikationen einzuspeisen und so Töne zu erzeugen.
{{</section>}}

{{<section title="Ableton.js">}}

AbletonJS stellt eine Schnittstelle zum Ableton Live Sequencer, die es ermöglicht über Javascript diverse Befehle zu schicken und so eine Live Session zu manipulieren.
{{</section>}}

{{<section title="React">}}

Wir verwendeten React, um die UI zu entwickeln. Im UI wird der "Area of interest Bereich" eingezeichnet. Wenn jemand dann diesen markierten Bereich betritt, reagiert die App.
{{</section>}}

{{<section title="JavaScript, HTML, CSS">}}

Die 3 Grundbausteine für Node.js und auch für das FrontEnd in React.
{{</section>}}
