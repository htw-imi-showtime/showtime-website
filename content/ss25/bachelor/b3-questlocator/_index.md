+++


project_id = "B3"
title = "Quest Locator"

# subtitle erscheint auf Übersichtsseite und Projektseite direkt unter dem Titel.
# kurzer 2. titel, der klar über den Inhalt des Projektes informiert
subtitle = "Visual Data Processing with Passthrough Cameras in Mixed Reality"

# der claim oder auch teaser erscheint auf Übersichtsseite und Projektseite nach Titel und Subtitle
claim = "Turn your view into a smart nutrition guide with real-time product info, AI insights, and sustainable choices."

# Abstract - erscheint oberhalb der Sections auf der Projektseite. 
# *** KANN WEGGELASSEN WERDEN ***, hat in der früheren Gliederung mehr sinn gemacht,
# kann aber genutzt werden, um etwas vor die erste Section zu setzen.
abstract = ""

# Properties for displaying the project in the project list
card_image = "logo_v5.jpg"

# Names are optional, team size is sufficient
team = ["Vanessa Pest", "Ole Kirchner", "Lennart Edlich", "Lorenz Brach", "Arton Troni", "Anton Basjukoff", "Friedrich Ludwig"]
# this can be just one or a list as with team:
supervisor = "Alexander Kramer"
draft = false


# e.g. github
source_link = "https://github.com/gelkoh/QuestLocator"
# link to a demo site / where your project is available.
# it's ok if it's temporary / just for the showtime, 
# just send a pr when you take the demo site down.
demo_link = ""
# website: if you have another project website (not demo)
website_link = ""
+++


{{<section title="Our Goal">}}
The task was to test of the Meta Quest 3’s built in Passthrough feature and come up with an idea for a useful product. After a planning phase we came up with our current idea to implement a Barcode Scanning Application. The goal was to build an application that promotes health and informed use of food and drinks. We wanted to have our program be as personal and easy to understand as possible. All you need to start are a Meta Quest 3 headset and your hands.

{{</section>}}


{{<section title="Process and Outcome">}}
**Process**

First we had to come up with an idea on how to use the feature in a useful way. A lot of different ideas were scrapped until we came across the OpenFoods API. We started by mapping user journeys and UML-diagrams to understand what features our application should include to be as inclusive and easy-to-use as possible. The next step was to divide the team based on strengths. Some were programming, while others were designing and coordinating the team. The first feature we had were working panels which came with the Meta SDK on which we based our many panels on. Weekly meetings with the team and with our supervisor helped move towards our end goal of designing and programming our application. We used provided Meta Quest 3's to test our program and to minimize errors.

{{<image src="in_app_footage_1.jpg" alt="In-App Footage Scan">}}
The required hand gesture to manually scan a barcode.
{{<image src="in_app_footage_2.jpg" alt="In-App Footage Panels">}}
A showcase of panels of a product.
{{<image src="in_app_footage_3.jpg" alt="In-App Footage Menu">}}A menu to navigate through the App.
A menu to navigate through the App.

**Tools and Ressources**

* The application was build on Unity Ver. 6000.0.46f1 with a C# Visual Studio extension.
* To access the Meta Quest 3 we used the Meta XR SDK, which also enabled us to create our own gestures.
* The Open-Food-Facts API is used to get the information about products and their barcode.
* ZXing makes it possible to read barcode.
* „Deutsche Gesellschaft für Ernährung e.V.“ provides the values for the daily allowance of nutrients of different activities, ages and body types.
* The AI-tool is made with Gemini.


**Product/Outcome**

We achieved to build an application for the Meta Quest which uses its Passthrough camera feature. With our program the camera scans product barcodes reliably and generates movable mixed-reality panels that provide information about ingredients, nutritional values and environmental impact. Furthermore, it’s possible to add information about yourself to check how much of your daily nutrition allowance a product includes. If you don’t understand a certain ingredient you can click it to get an explanation in different difficulties from easy to scientific generated by a built-in AI feature. To include first time VR users we included a simple-to-understand tutorial. The design can be changed if you prefer light or dark mode. It is possible to close every panel individually or all at once with a clear-all button.
{{</section>}}


{{<section title="Team">}}
{{</section>}}
{{<gallery>}}
{{<team-member image="vanessa.jpg" name="Vanessa">}}
{{<team-member image="ole.jpg" name="Ole">}}
{{<team-member image="lennart.jpg" name="Lennart">}}
{{<team-member image="arton.jpg" name="Arton">}}
{{<team-member image="anton.jpg" name="Anton">}}
{{<team-member image="lorenz.jpg" name="Lorenz">}}
{{<team-member image="friedrich.jpg" name="Friedrich">}}
{{</gallery>}}



{{<section title="Special Thanks">}}
. . . to Creative Media and Alexander Kramer for providing the Meta Quest 3‘s and supervision during our project!
{{</section>}}